---
title: "浅识扩散模型"
date: 2025-05-09T10:00:00+08:00
draft: false
tags: ["技术", "机器学习"]
categories: ["笔记"]
math: true
---


## 1. DDPM的核心思想

DDPM是一种基于概率的生成模型，其核心思想是通过模拟一个**前向扩散过程**（逐渐向数据添加噪声）和一个**逆向去噪过程**（从噪声恢复数据）来生成高质量样本。DDPM的训练目标是学习逆向过程的概率分布，使其能够从纯噪声中逐步生成逼真的样本。

- **前向过程**（Forward Process）：从真实数据 $ x_0 $ 开始，逐步添加高斯噪声，经过 $ T $ 步后，数据变成近似的各向同性高斯噪声。
- **逆向过程**（Reverse Process）：从高斯噪声 $ x_T $ 开始，逐步去噪，恢复到原始数据 $ x_0 $。

DDPM的关键是逆向过程的概率分布 $ p_\theta(x_{t-1}|x_t) $ 难以直接建模，因此通过训练一个神经网络来逼近它，并通过优化一个变分下界（variational lower bound）来学习参数。

---

## 2. 前向扩散过程的推导

### 2.1 前向过程的定义

前向过程是一个马尔可夫链，定义为从真实数据 $ x_0 $ 到噪声 $ x_T $ 的逐步加噪过程。每一步添加一个高斯噪声，形式为：

{{< rawhtml >}}
$$ q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I) $$
{{< /rawhtml >}}

其中：
- $ x_t $ 是第 $ t $ 步的加噪数据。
- $ \beta_t \in (0, 1) $ 是第 $ t $ 步的噪声调度参数，控制每一步添加的噪声量。
- $ \sqrt{1-\beta_t} x_{t-1} $ 是均值，意味着数据被稍微缩放。
- $ \beta_t I $ 是方差，表示添加的噪声强度。

直观来说，每一步都在 $ x_{t-1} $ 的基础上乘以一个小于1的系数（使信号衰减），并加上一个高斯噪声。

### 2.2 多步前向过程

由于前向过程是马尔可夫链，我们可以写出从 $ x_0 $ 到 $ x_t $ 的联合分布：

{{< rawhtml >}}
$$ q(x_{1:t} | x_0) = \prod_{s=1}^t q(x_s | x_{s-1}) $$
{{< /rawhtml >}}

更重要的是，我们可以直接计算从 $ x_0 $ 到任意 $ x_t $ 的边缘分布 $ q(x_t | x_0) $。DDPM中通过巧妙的参数化，得到了一个非常方便的闭合形式。

定义：
{{< rawhtml >}}
$$ \alpha_t = 1 - \beta_t, \quad \bar{\alpha}_t = \prod_{s=1}^t \alpha_s $$
{{< /rawhtml >}}

那么，$ q(x_t | x_0) $ 可以表示为：

{{< rawhtml >}}
$$ q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I) $$
{{< /rawhtml >}}

**推导过程**：
- 假设 
  {{< rawhtml >}}
  $$ x_{t-1} \sim \mathcal{N}(\sqrt{\bar{\alpha}_{t-1}} x_0, (1 - \bar{\alpha}_{t-1}) I) $$
  {{< /rawhtml >}}
  我们需要计算 $ x_t $
- 根据前向过程定义，$ x_t = \sqrt{\alpha_t} x_{t-1} + \sqrt{\beta_t} \epsilon $，其中 $ \epsilon \sim \mathcal{N}(0, I) $。
  将 {{< rawhtml >}}
  $$ x_{t-1} = \sqrt{\bar{\alpha}_{t-1}} x_0 + \sqrt{1 - \bar{\alpha}_{t-1}} \epsilon_{t-1} $$ {{</rawhtml>}}代入，得到：
  {{< rawhtml >}}
  $$ x_t = \sqrt{\alpha_t} (\sqrt{\bar{\alpha}_{t-1}} x_0 + \sqrt{1 - \bar{\alpha}_{t-1}} \epsilon_{t-1}) + \sqrt{\beta_t} \epsilon $$
  {{< /rawhtml >}}
  {{< rawhtml >}}
  $$ = \sqrt{\alpha_t \bar{\alpha}_{t-1}} x_0 + \sqrt{\alpha_t (1 - \bar{\alpha}_{t-1})} \epsilon_{t-1} + \sqrt{\beta_t} \epsilon $$
  {{< /rawhtml >}}
- 由于 {{<rawhtml>}}$ \bar{\alpha}_t = \alpha_t \bar{\alpha}_{t-1} ${{</rawhtml>}}，均值项为 $ \sqrt{\bar{\alpha}_t} x_0 $。
- 方差项需要合并两个高斯噪声的方差：
  {{< rawhtml >}}
  $$ \text{Var}(x_t) = \alpha_t (1 - \bar{\alpha}_{t-1}) + \beta_t = 1 - \alpha_t \bar{\alpha}_{t-1} = 1 - \bar{\alpha}_t $$
  {{< /rawhtml >}}

因此，$ x_t $ 可以直接从 $ x_0 $ 采样：

{{< rawhtml >}}
$$ x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I) $$
{{< /rawhtml >}}

这个公式非常重要，因为它允许我们从真实数据 $ x_0 $ 直接生成任意时间步 $ t $ 的加噪数据，而无需逐步模拟整个马尔可夫链。

---

## 3. 逆向去噪过程的建模

### 3.1 逆向过程的定义

逆向过程也是一个马尔可夫链，定义为从噪声 $ x_T $ 逐步去噪到数据 $ x_0 $：

{{< rawhtml >}}
$$ p_\theta(x_{0:T}) = p(x_T) \prod_{t=1}^T p_\theta(x_{t-1} | x_t) $$
{{< /rawhtml >}}

其中：
- $ p(x_T) = \mathcal{N}(0, I) $，假设 $ T $ 足够大，$ x_T $ 近似于各向同性高斯噪声。
- $ p_\theta(x_{t-1} | x_t) $ 是参数化的逆向转移概率，通常假设为高斯分布：

{{< rawhtml >}}
$$ p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t)) $$
{{< /rawhtml >}}

DDPM的目标是学习参数 $ \theta $，使得 $ p_\theta(x_0) $ 尽可能接近真实数据分布 $ q(x_0) $。

### 3.2 真实逆向分布

理论上，真实逆向分布 $ q(x_{t-1} | x_t, x_0) $ 可以通过贝叶斯公式计算：

{{< rawhtml >}}
$$ q(x_{t-1} | x_t, x_0) = \frac{q(x_t | x_{t-1}, x_0) q(x_{t-1} | x_0)}{q(x_t | x_0)} $$
{{< /rawhtml >}}

由于 $ q(x_t | x_{t-1}, x_0) = q(x_t | x_{t-1}) $，代入前向过程的定义：

{{< rawhtml >}}
$$ q(x_{t-1} | x_t, x_0) \propto \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, \beta_t I) \cdot \mathcal{N}(x_{t-1}; \sqrt{\bar{\alpha}_{t-1}} x_0, (1 - \bar{\alpha}_{t-1}) I) $$
{{< /rawhtml >}}

经过高斯分布的乘积运算（略去繁琐推导），可以得到 $ q(x_{t-1} | x_t, x_0) $ 也是高斯分布，其均值和方差为：

{{< rawhtml >}}
$$ \mu_q = \frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1 - \bar{\alpha}_t} x_0 + \frac{\sqrt{\alpha_t} (1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} x_t $$
{{< /rawhtml >}}

{{< rawhtml >}}
$$ \Sigma_q = \frac{(1 - \bar{\alpha}_{t-1}) \beta_t}{1 - \bar{\alpha}_t} I $$
{{< /rawhtml >}}

然而，这个真实逆向分布依赖于 $ x_0 $，而在采样时我们无法直接访问 $ x_0 $。因此，DDPM通过神经网络来逼近这个分布。

---

## 4. 损失函数的推导

### 4.1 变分下界（ELBO）

DDPM的训练目标是最大化数据似然 $ p_\theta(x_0) $。直接优化似然很困难，因此我们优化其对数似然的变分下界（Evidence Lower Bound, ELBO）。ELBO的推导基于KL散度：

{{< rawhtml >}}
$$ \log p_\theta(x_0) \geq \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \log \frac{p_\theta(x_{0:T})}{q(x_{1:T}|x_0)} \right] $$
{{< /rawhtml >}}

展开后，ELBO可以写为：

{{< rawhtml >}}
$$ L = \mathbb{E}_q \left[ \log p_\theta(x_0 | x_1) + \sum_{t=2}^T \log \frac{p_\theta(x_{t-1} | x_t)}{q(x_{t-1} | x_t, x_0)} + \log \frac{p(x_T)}{q(x_T | x_0)} \right] $$
{{< /rawhtml >}}

将其拆分为三部分：
1. **重构项**：$ L_0 = -\log p_\theta(x_0 | x_1) $，表示从 $ x_1 $ 重构 $ x_0 $ 的误差。
2. **去噪匹配项**：$ L_{t-1} = D_{KL}(q(x_{t-1} | x_t, x_0) || p_\theta(x_{t-1} | x_t)) $，表示逆向分布与真实逆向分布的KL散度。
3. **先验匹配项**：$ L_T = D_{KL}(q(x_T | x_0) || p(x_T)) $，表示 $ x_T $ 与标准高斯分布的匹配。

当 $ T $ 足够大时，$ q(x_T | x_0) \approx \mathcal{N}(0, I) $，因此 $ L_T \approx 0 $，可以忽略。

### 4.2 简化损失函数

DDPM的关键创新在于简化 $ L_{t-1} $。假设逆向过程的均值为：

{{< rawhtml >}}
$$ \mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) $$
{{< /rawhtml >}}

其中 $ \epsilon_\theta(x_t, t) $ 是神经网络预测的噪声。方差通常取为 $ \Sigma_\theta = \beta_t I $ 或其他调度形式。

通过代入 {{< rawhtml >}}$ x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon $ {{< /rawhtml >}}，并计算KL散度，DDPM发现优化 $ L_{t-1} $ 等价于最小化以下损失：

{{< rawhtml >}}
$$ L_{t-1} \propto \mathbb{E}_{x_0, \epsilon} \left[ \left\| \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t) \right\|^2 \right] $$
{{< /rawhtml >}}

最终，DDPM的简化损失函数（忽略常数项）为：

{{< rawhtml >}}
$$ L_{\text{simple}} = \mathbb{E}_{t \sim [1,T], x_0, \epsilon} \left[ \left\| \epsilon - \epsilon_\theta(x_t, t) \right\|^2 \right] $$
{{< /rawhtml >}}

其中：
- $ t \sim \text{Uniform}(1, T) $，随机采样时间步。
- $ x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon $，通过前向过程生成。
- $ \epsilon_\theta(x_t, t) $ 是神经网络预测的噪声。

这个损失函数的直觉是：训练神经网络预测加到 $ x_0 $ 上的噪声 $ \epsilon $，从而间接学习逆向去噪过程。

---

## 5. 采样过程的推导

### 5.1 逆向采样公式

训练完成后，我们使用逆向过程从噪声 $ x_T \sim \mathcal{N}(0, I) $ 开始采样，逐步生成 $ x_{T-1}, x_{T-2}, \dots, x_0 $。逆向过程的每一步为：

{{< rawhtml >}}
$$ p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t)) $$
{{< /rawhtml >}}

均值 $ \mu_\theta $ 由神经网络预测的噪声 $ \epsilon_\theta $ 计算：

{{< rawhtml >}}
$$ \mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) $$
{{< /rawhtml >}}

方差 $ \Sigma_\theta $ 通常取为 $ \beta_t I $ 或其他调度（如DDIM中使用的确定性采样）。

采样公式为：

{{< rawhtml >}}
$$ x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sqrt{\beta_t} z, \quad z \sim \mathcal{N}(0, I) $$
{{< /rawhtml >}}

### 5.2 采样算法

完整的采样算法如下：
1. 初始化 $ x_T \sim \mathcal{N}(0, I) $。
2. 对于 $ t = T, T-1, \dots, 1 $：
   - 计算 $ \epsilon_\theta(x_t, t) $。
   - 计算均值 $ \mu_\theta(x_t, t) $。
   - 采样 $ x_{t-1} \sim \mathcal{N}(\mu_\theta(x_t, t), \beta_t I) $。
3. 返回 $ x_0 $。

### 5.3 改进：DDIM

DDPM的采样过程需要 $ T $ 步，计算成本高。Denoising Diffusion Implicit Models (DDIM) 提出了一种确定性采样方法，通过修改逆向过程，允许更少的采样步数（例如 50 或 100 步），显著加速生成过程，同时保持生成质量。

---

## 6. 总结与直觉

### 6.1 损失函数的直觉
- DDPM的损失函数本质上是让神经网络预测前向过程中添加的噪声 $ \epsilon $。
- 通过最小化预测噪声与真实噪声的均方误差，模型学会了如何从 $ x_t $ 恢复 $ x_{t-1} $，从而间接逼近逆向分布。

### 6.2 采样过程的直觉
- 采样过程类似于“从噪声中雕刻数据”。每一步，模型根据当前加噪状态 $ x_t $ 预测噪声，并利用它来估计更接近真实数据的 $ x_{t-1} $。
- 整个过程是一个逐步去噪的过程，最终从纯噪声生成逼真的样本。

### 6.3 数学美感
- 前向过程的闭合形式（直接从 $ x_0 $ 到 $ x_t $）大大简化了训练和采样。
- 变分下界的简化使得优化目标变得直观且易于实现。

---

## 7. 代码实现（简要）

以下是一个简化的DDPM训练和采样的伪代码，供参考：

```python
# 训练
def train_ddpm(model, data_loader, num_epochs, T, betas):
    for epoch in range(num_epochs):
        for x0 in data_loader:
            t = torch.randint(1, T+1, (x0.shape[0],))  # 随机时间步
            epsilon = torch.randn_like(x0)  # 随机噪声
            alpha_bar_t = torch.prod(1 - betas[:t])  # 计算 $ \bar{\alpha}_t $
            xt = sqrt(alpha_bar_t) * x0 + sqrt(1 - alpha_bar_t) * epsilon  # 前向过程
            loss = mse_loss(epsilon, model(xt, t))  # 预测噪声的损失
            optimize(loss)

# 采样
def sample_ddpm(model, num_samples, T, betas):
    xt = torch.randn(num_samples, ...)  # 从高斯噪声开始
    for t in range(T, 0, -1):
        epsilon_theta = model(xt, t)  # 预测噪声
        alpha_t = 1 - betas[t]
        mu_theta = (xt - betas[t] / sqrt(1 - alpha_bar_t) * epsilon_theta) / sqrt(alpha_t)
        xt = mu_theta + sqrt(betas[t]) * torch.randn_like(xt)  # 逆向采样
    return xt